services:
  inventorydb:
    image: mysql
    container_name: inventory_db
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
    ports:
      - "3301:3306"
    volumes:
      - inventorydb:/data/db

  filterdb:
    image: mongo:5.0.13
    container_name: filter_db
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_ROOT_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_ROOT_PASSWORD}
      MONGO_INITDB_DATABASE: filterdb
    volumes:
      - filterdb:/data/db

  authdb:
    image: mysql
    container_name: auth_ecommerce_db
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
    ports:
      - "3305:3306"
    volumes:
      - authdb:/data/db

  blackliststore:
    image: redis
    container_name: blacklist_store
    ports:
      - "6379:6379"
    environment:
      REDIS_PASSWORD: ${REDIS_PASSWORD}
    command: [ "redis-server", "--requirepass", "${REDIS_PASSWORD}" ]
    volumes:
      - blacklist:/data

  # ? Graylog Configuration
  mongo:
    image: mongo:5.0.13
    networks:
      - graylog

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch-oss:7.10.2
    environment:
      - http.host=0.0.0.0
      - transport.host=localhost
      - network.host=0.0.0.0
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    networks:
      - graylog

  graylog:
    image: graylog/graylog:6.0.4
    environment:
      GRAYLOG_ELASTICSEARCH_HOSTS: http://elasticsearch:9200
      GRAYLOG_HTTP_EXTERNAL_URI: http://127.0.0.1:9000/
      GRAYLOG_PASSWORD_SECRET: ${GRAYLOG_PASSWORD_SECRET}
      GRAYLOG_ROOT_PASSWORD_SHA2: ${GRAYLOG_ROOT_PASSWORD_SHA2}
    networks:
      - graylog
    depends_on:
      - mongo
      - elasticsearch
    ports:
      - "9000:9000"
      - "12201:12201/udp"

  # ? Kafka Configuration
  kafka:
    image: apache/kafka:4.1.1
    container_name: kafka_broker
    hostname: kafka
    ports:
      - "9092:9092"
    volumes:
      - kafka_data:/var/lib/kafka/data
    environment:
      # Single node / local dev için gerekli olanlar
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_NODE_ID: "1"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:29093"

      # Listener'lar: container içi (29092), controller (29093), host dışarı açılan (9092)
      KAFKA_LISTENERS: "PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"

      # Bitnami'deki AUTO_CREATE_TOPICS_ENABLE karşılığı
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"

      # Single broker olduğun için replication/min.isr değerleri (yoksa topic create ederken patlayabiliyor)
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: "1"
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: "0"

      # KRaft storage için cluster id (sabit de verebilirsin, local için sorun değil)
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"

      # Data path (volume'a denk gelecek şekilde)
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"

  prometheus:
    image: prom/prometheus
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml

volumes:
  inventorydb:
    driver: local
  filterdb:
    driver: local
  authdb:
    driver: local
  blacklist:
    driver: local
  kafka_data:
    driver: local

networks:
  graylog:
    driver: bridge